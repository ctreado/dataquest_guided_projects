{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Spam Filter for SMS Messages\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this project, we use the multinomial Naive Bayes algorithm to build a spam filter for SMS messages. The Naive Bayes algorithm is used to teach the computer how to classify new messages as spam or non-spam based on a set of human-classified messages. Using the algorithm and a finite dataset, the computer learns how humans classify messages and then applies this knowledge to estimate probabilities of new messages belonging to one class or another. The goal of this project is to create a spam filter that accurately classifies messages at least 80% of the time.\n",
    "\n",
    "For our spam filter, we use the multinomial Naive Bayes algorithm and a dataset of 5,572 human-classified SMS messages to teach the computer how to decipher between spam and non-spam. The dataset, put together by Tiago A. Almeida and Jose Maria Gomez Hidalgo, can be downloaded from [The UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection) or from [this link](https://dq-content.s3.amazonaws.com/433/SMSSpamCollection). More details on the dataset, including its collection, usage, and associated publications, can be found [here](https://www.dt.fee.unicamp.br/~tiago/smsspamcollection/#composition)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Dataset\n",
    "\n",
    "We begin our project by reading in and exploring the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "sms_spam = pd.read_csv('SMSSpamCollection', sep='\\t', header=None,\n",
    "                       names=['Label', 'SMS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_spam.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spam_percent = ((sms_spam['Label'] == 'spam').sum() / \n",
    "                sms_spam.shape[0] * 100)\n",
    "ham_percent = ((sms_spam['Label'] == 'ham').sum() /\n",
    "               sms_spam.shape[0] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.406317300789663 86.59368269921033\n"
     ]
    }
   ],
   "source": [
    "print(spam_percent, ham_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of 5,572 rows and 2 columns. Each row corresponds to a distinct SMS message. The first column contains the classification or label of the SMS message, with 'spam' indicating a spam message and 'ham' indicating a non-spam message. The second column contains the SMS message itself. Of the 5,572 human-classified SMS messages, 13.4% are spam, and 86.6% are non-spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Generating Training and Test Sets\n",
    "\n",
    "Before we can begin building our spam filter software, we need to divide our dataset into two separate pieces: a **training set** and a **test set**. The training set will be used to teach, or \"train\", the computer to classify new messages, and the test set will be used  to assess the efficiency of the filter, i.e. how well the computer classified new messages.\n",
    "\n",
    "Splitting the dataset this way is essential in order to avoid bias in evaluating the final filter designed from the training set. With a dedicated test set, we will be able to directly compare the classifications produced by the algorithm to those performed by humans in order to calculate the efficieny of the spam filter.\n",
    "\n",
    "For this project, we will randomly select 80% of the dataset to be training data and 20% to be test data. This allows us to train on as much data as possible while still maintaining enough data to test with later. We randomize and split the dataset below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# randomize entire dataset\n",
    "sms_rndm = sms_spam.sample(frac=1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split randomized dataset into training and test sets\n",
    "index_80p = round(sms_rndm.shape[0] * 0.8)\n",
    "sms_train = sms_rndm[0:index_80p].reset_index(drop=True)\n",
    "sms_test = sms_rndm[index_80p:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4458, 2) (1114, 2)\n"
     ]
    }
   ],
   "source": [
    "# check sizes of new sets\n",
    "print(sms_train.shape, sms_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.458950201884253 86.54104979811575\n",
      "13.195691202872531 86.80430879712748\n"
     ]
    }
   ],
   "source": [
    "# find percentage of spam/ham in each set\n",
    "train_spam_percent = ((sms_train['Label'] == 'spam').sum() / \n",
    "                       sms_train.shape[0] * 100)\n",
    "train_ham_percent = ((sms_train['Label'] == 'ham').sum() /\n",
    "                      sms_train.shape[0] * 100)\n",
    "test_spam_percent = ((sms_test['Label'] == 'spam').sum() / \n",
    "                      sms_test.shape[0] * 100)\n",
    "test_ham_percent = ((sms_test['Label'] == 'ham').sum() /\n",
    "                     sms_test.shape[0] * 100)\n",
    "print(train_spam_percent, train_ham_percent)\n",
    "print(test_spam_percent, test_ham_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new training and test sets contain 4,458 and 1,114 rows, respectively, and approximately the same percentages of spam and non-spam messages each as the original full dataset. The similar percentages in each set indicate they are both representative of the whole dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Data\n",
    "\n",
    "We will train the data to classify messages by calculating the conditional probability of a message belonging to a certain class given the words it contains using Bayes's Theorem: \n",
    "$$P(\\mathrm{class} ~|~ w_1,...,w_n) = P(\\mathrm{class}) \\times \\prod_{i=1}^n P(w_i ~|~ \\mathrm{class}).$$\n",
    "\n",
    "In order to perform the necessary probability calculations, we first need to clean and reformat the training data such that we can more easily extract the information needed. Below, we transform the `SMS` column into a series of columns representing the entire vocabulary contained in all of the SMS messages, with each column corresponding to a single unique word in the vocabulary. The value of the entry in each of these new columns then represents the count of the corresponding word in the individual message of the given row. Capitalization and punctuation are ignored in the vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin the data cleaning by removing all punctuation from the SMS messages and transforming the messages to all lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove punctuation and transform to lowercase\n",
    "import re\n",
    "sms_train['SMS'] = sms_train['SMS'].str.replace('\\W', ' ')\n",
    "sms_train['SMS'] = sms_train['SMS'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep  by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes  princess  are you going to make me moan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>havent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth   there s a card on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                       yep  by the pretty sculpture\n",
       "1   ham      yes  princess  are you going to make me moan \n",
       "2   ham                         welp apparently he retired\n",
       "3   ham                                            havent \n",
       "4   ham  i forgot 2 ask ü all smth   there s a card on ..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we build a vocabulary list of all of the unique words in the SMS messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build vocabulary list for messages in training set\n",
    "sms_train['SMS'] = sms_train['SMS'].str.split()\n",
    "vocabulary = []\n",
    "for sms in sms_train['SMS']:\n",
    "    for word in sms:\n",
    "        vocabulary.append(str(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform to list of unique words\n",
    "vocabulary = set(vocabulary)\n",
    "vocabulary = list(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create a dictionary that maps each unique word in the vocabulary to a list of the number of times it appears in each SMS message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_counts_per_sms = {vocab : [0] * len(sms_train['SMS']) \n",
    "                       for vocab in vocabulary}\n",
    "for index, sms in enumerate(sms_train['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can use the dictionary to transform the dataset into the desired format, with each message represented by a series of word counts from the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sms_train_word_counts_per_sms = pd.DataFrame(word_counts_per_sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sms_train_reform = pd.concat([sms_train['Label'], \n",
    "                              sms_train_word_counts_per_sms], \n",
    "                             axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000pes</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0089</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>02</th>\n",
       "      <th>0207</th>\n",
       "      <th>...</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>é</th>\n",
       "      <th>ú1</th>\n",
       "      <th>ü</th>\n",
       "      <th>〨ud</th>\n",
       "      <th>鈥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label  0  00  000  000pes  008704050406  0089  01223585334  02  0207 ...  \\\n",
       "0   ham  0   0    0       0             0     0            0   0     0 ...   \n",
       "1   ham  0   0    0       0             0     0            0   0     0 ...   \n",
       "2   ham  0   0    0       0             0     0            0   0     0 ...   \n",
       "3   ham  0   0    0       0             0     0            0   0     0 ...   \n",
       "4   ham  0   0    0       0             0     0            0   0     0 ...   \n",
       "\n",
       "   zindgi  zoe  zogtorius  zouk  zyada  é  ú1  ü  〨ud  鈥  \n",
       "0       0    0          0     0      0  0   0  0    0  0  \n",
       "1       0    0          0     0      0  0   0  0    0  0  \n",
       "2       0    0          0     0      0  0   0  0    0  0  \n",
       "3       0    0          0     0      0  0   0  0    0  0  \n",
       "4       0    0          0     0      0  0   0  2    0  0  \n",
       "\n",
       "[5 rows x 7784 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_train_reform.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Calculating Probabilities\n",
    "\n",
    "Now that the training dataset is in the proper format, we are ready to begin calculating the probability equations needed for the Naive Bayes algorithm of our spam filter. The algorithm classifies new messages by comparing the conditional probabilities of a new message being either spam or non-spam given the words the message contains. In other words, we need to calculate the following probability equations:\n",
    "\n",
    "$$P(\\mathrm{Spam/Ham ~|~ w_1,...,w_n}) \\propto P(\\mathrm{Spam/Ham}) \\cdot \\prod_{i=1}^n P(w_i ~|~ \\mathrm{Spam/Ham}),$$\n",
    "\n",
    "where \n",
    "\n",
    "$$P(\\mathrm{Spam/Ham}) = \\frac{\\mathrm{number~of~Spam/Ham~classified~training~set~messages}}{\\mathrm{number~of~training~set~messages}},$$\n",
    "\n",
    "and\n",
    "\n",
    "$$P(w_i ~|~ \\mathrm{Spam/Ham}) = \\frac{N_{w_i ~|~ \\mathrm{Spam/Ham}} + \\alpha}{N_\\mathrm{Spam/Ham} + \\alpha \\cdot N_\\mathrm{Vocabulary}}.$$\n",
    "\n",
    "$N_\\mathrm{Spam/Ham}$ is the total number of words in all messages of a given classification (either spam or non-spam), $N_{w_i ~|~ \\mathrm{Spam/Ham}}$ is the number of times the given word occurs in all messages of the specified classification, $N_\\mathrm{vocabulary}$ is the number of unique words in the vocabulary, and $\\alpha$ is a smoothing parameter. For our filter, we use Lapalace smoothing, where $\\alpha = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Constants\n",
    "\n",
    "We begin by calculating the probability equations' constants, the values of which remain fixed, assuming no changes are made to the training set, across all new messages, regardless of their contents. The following are constants of the probability equations:\n",
    "- $P(\\mathrm{Spam})$: the probability of a message being spam, or the fraction of messages in the training set that are classified as spam;\n",
    "- $P(\\mathrm{Ham})$: the probability of a message being non-spam, or the fraction of messages in the training set that are classified as non-spam;\n",
    "- $N_\\mathrm{Spam}$: the total number of words in all spam messages;\n",
    "- $N_\\mathrm{Ham}$: the total number of words in all non-spam messages;\n",
    "- $N_\\mathrm{Vocabulary}$: the number of unique words in the vocabulary;\n",
    "- $\\alpha = 1$: the Laplace smoothing parameter.\n",
    "\n",
    "We calculate and print their values below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_spam = ((sms_train_reform['Label'] == 'spam').sum() /\n",
    "          sms_train_reform.shape[0])\n",
    "p_ham = ((sms_train_reform['Label'] == 'ham').sum() /\n",
    "         sms_train_reform.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sms_train_reform['word_ct'] = sms_train_reform.iloc[:,1:].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_spam = (sms_train_reform\n",
    "          [sms_train_reform['Label'] == 'spam']['word_ct'].sum())\n",
    "n_ham = (sms_train_reform\n",
    "         [sms_train_reform['Label'] == 'ham']['word_ct'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_vocab = len(vocabulary)\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13458950201884254 0.8654104979811574 15190 57237 7783 1\n"
     ]
    }
   ],
   "source": [
    "print(p_spam, p_ham, n_spam, n_ham, n_vocab, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Parameters\n",
    "\n",
    "Next, we calculate the parameters $P(w_i ~|~ \\mathrm{Spam/Ham})$, or the probabilities for each word in our vocabulary. These parameters values also remain fixed for all new messages as long as our training set does not change. This means we can calculate the conditional probabilities given the message is spam or non-spam for all the words in our vocabulary of our training set. From these pre-calculated parameters and constants, our filter will then be able to very quickly classify a new message as spam or not.\n",
    "\n",
    "Below, we calculate the parameters \n",
    "$$P(w_i ~|~ \\mathrm{Spam/Ham}) = \\frac{N_{w_i ~|~ \\mathrm{Spam/Ham}} + \\alpha}{N_\\mathrm{Spam/Ham} + \\alpha \\cdot N_\\mathrm{Vocabulary}}$$\n",
    "\n",
    "for each word in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialize probability dictionaries\n",
    "spam_dict = {vocab : 0 for vocab in vocabulary}\n",
    "ham_dict = {vocab : 0 for vocab in vocabulary}\n",
    "\n",
    "# split training set into spam and non-spam messages\n",
    "train_spam = sms_train_reform[sms_train_reform['Label'] == 'spam']\n",
    "train_ham = sms_train_reform[sms_train_reform['Label'] == 'ham']\n",
    "\n",
    "## sum number of times each word occurs in each message type\n",
    "#train_spam_sum = train_spam.sum()\n",
    "#train_ham_sum = train_ham.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loop over unique words in vocabulary\n",
    "for word in vocabulary:\n",
    "    # count number of times word appears in messages\n",
    "    n_word_spam = train_spam[word].sum()\n",
    "    n_word_ham = train_ham[word].sum()\n",
    "    \n",
    "    # calculate parameters\n",
    "    p_word_spam = (n_word_spam + alpha) / (n_spam + alpha * n_vocab)\n",
    "    p_word_ham = (n_word_ham + alpha) / (n_ham + alpha * n_vocab)\n",
    "    \n",
    "    # add parameters to dictionaries\n",
    "    spam_dict[word] = p_word_spam\n",
    "    ham_dict[word] = p_word_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Spam Filter\n",
    "\n",
    "With the necessary probability constants and parameters in hand, we are ready to begin building the spam filter. We define the spam filter as a function that takes a new message as input, calculates the probabilities that the message is spam and non-spam given the words contained, compares those probabilities, and outputs a classification for the given message based on which probability is larger. The probabilities the spam filter calculates in the function are\n",
    "$$P(\\mathrm{Spam/Ham ~|~ w_1,...,w_n}) \\propto P(\\mathrm{Spam/Ham}) \\cdot \\prod_{i=1}^n P(w_i ~|~ \\mathrm{Spam/Ham}),$$\n",
    "\n",
    "where the probabilities $P(\\mathrm{Spam/Ham})$ and $P(w_i ~|~ \\mathrm{Spam/Ham})$ have already been calculated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(message):\n",
    "    \"\"\"\n",
    "    Classify message as spam or ham (non-spam).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    message : str\n",
    "        Message to classify.\n",
    "    \"\"\"\n",
    "    \n",
    "    # clean msg: remove punctuation, make lowercase, split into list\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "    \n",
    "    # calculate p_spam/ham_given_message\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    # --> multiply probs by probs for given word in dict\n",
    "    for word in message:\n",
    "        if word in spam_dict:\n",
    "            p_spam_given_message *= spam_dict[word]\n",
    "        if word in ham_dict:\n",
    "            p_ham_given_message *= ham_dict[word]\n",
    "    \n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham\"message):', p_ham_given_message)\n",
    "    \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal probabilities; have a human classify this!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 1.3481290211300841e-25\n",
      "P(Ham\"message): 1.9368049028589875e-27\n",
      "Label: Spam\n",
      "P(Spam|message): 2.4372375665888117e-25\n",
      "P(Ham\"message): 3.687530435009238e-21\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "msg1 = 'WINNER!! This is the secret code to unlock the money: C3421.'\n",
    "msg2 = \"Sounds good, Tom, then see u there\"\n",
    "classify(msg1)\n",
    "classify(msg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Filter\n",
    "\n",
    "With our spam filter now in place, we want to test its capabiities on our test set of data. Below, we modify our filtering function to return, rather than print, a classification for each input message. We then run the filter over all the messages in our test set, the results of which we then compare to the actual human-classified label associated with each message in order to calculate the accuracy of our filter. \n",
    "\n",
    "The accuracy, defined as the fraction of messages that are correctly classified, is a metric of how well the predicted values compare to the actual values in our dataset, or of how well our spam filter performs in terms of classifying new messages as spam or non-spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_test_set(message):\n",
    "    \"\"\"\n",
    "    Classify message as spam or ham (non-spam).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    message : str\n",
    "        Message to classify.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Classification of message as spam or non-spam.\n",
    "    \"\"\"\n",
    "    \n",
    "    # clean msg: remove punctuation, make lowercase, split into list\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "    \n",
    "    # calculate p_spam/ham_given_message\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    # --> multiply probs by probs for given word in dict\n",
    "    for word in message:\n",
    "        if word in spam_dict:\n",
    "            p_spam_given_message *= spam_dict[word]\n",
    "        if word in ham_dict:\n",
    "            p_ham_given_message *= ham_dict[word]\n",
    "    \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham          Later i guess. I needa do mcat study too.       ham\n",
       "1   ham             But i haf enuff space got like 4 mb...       ham\n",
       "2  spam  Had your mobile 10 mths? Update to latest Oran...      spam\n",
       "3   ham  All sounds good. Fingers . Makes it difficult ...       ham\n",
       "4   ham  All done, all handed in. Don't know if mega sh...       ham"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict classifications for test set\n",
    "sms_test['predicted'] = sms_test['SMS'].apply(classify_test_set)\n",
    "sms_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9874326750448833\n"
     ]
    }
   ],
   "source": [
    "# measure accuracy of spam filter\n",
    "correct = 0\n",
    "total = sms_test.shape[0]\n",
    "for row in sms_test.iterrows():\n",
    "    row = row[1]\n",
    "    if row['Label'] == row['predicted']:\n",
    "        correct += 1\n",
    "accuracy = correct / total\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy for our Naive Bayes spam filter is 98.74%, which is excellent!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this project, we built a spam filter for SMS messages using the multinomial Naive Bayes algorithm. Our filter had an accuracy of nearly 99% for our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
