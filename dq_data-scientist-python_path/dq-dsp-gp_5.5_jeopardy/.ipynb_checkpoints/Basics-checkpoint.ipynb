{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# How to Win Jeopardy\n",
    "\n",
    "## Introduction\n",
    "\n",
    "We would like to compete on Jeopardy, the popular TV game show where contestants answer trivia questions to win money. To develop a strategy to help us win, we analyze a dataset of 20,000 past Jeopardy questions, looking for any patterns in the questions that may appear.\n",
    "\n",
    "The dataset we are working with is a subset of a full dataset of Jeopardy questions, which can be downloaded from [this Reddit post](https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/). Each row of the dataset represents an individual question from an individual episode of the the show and contains the following columns:\n",
    "- `Show Number` -- the episode number of the show in which the question appeared;\n",
    "- `Air Date` -- the date on which the episode aired;\n",
    "- `Round` -- the round of Jeopardy in which the question was posed;\n",
    "- `Category` -- the category of question, e.g;\n",
    "- `Value` -- the monetary value, in US dollars, of the correct answer to the question;\n",
    "- `Question` -- the text of the question itself;\n",
    "- `Answer` -- the text of the answer to the question.\n",
    "\n",
    "**COME BACK AND FILL IN GOAL / RESULTS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring and Cleaning the Dataset\n",
    "\n",
    "Before we begin the analysis, we read in, explore, and clean the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category  Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
       "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
       "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
       "2  The city of Yuma in this state has a record av...     Arizona  \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in and explore dataset\n",
    "import pandas as pd\n",
    "jeopardy = pd.read_csv('jeopardy.csv')\n",
    "# view first five rows\n",
    "jeopardy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19999, 7)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view shape\n",
    "jeopardy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
       "       ' Question', ' Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view columns\n",
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice first that some of the column names contain erroneous leading spaces. Let's remove the spaces for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question',\n",
       "       'Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean up column names\n",
    "new_columns = []\n",
    "for col in jeopardy.columns:\n",
    "    new_columns.append(col.strip())\n",
    "jeopardy.columns = new_columns\n",
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next want to normalize the text columns. This entails transforming the text to lowercase and removing all punctuation. Below, we write a function to perform the normalization and then apply the function to the `Question` and `Answer` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import regular expression library\n",
    "import re\n",
    "\n",
    "# define normalization function\n",
    "def normalize_text(text):\n",
    "    \"\"\"\n",
    "    Normalize text by converting to lowercase and removing \n",
    "    punctuation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        Text to be normalized.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Normalized text.\n",
    "    \"\"\"\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>clean_question</th>\n",
       "      <th>clean_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "      <td>for the last 8 years of his life  galileo was ...</td>\n",
       "      <td>copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "      <td>no  2  1912 olympian  football star at carlisl...</td>\n",
       "      <td>jim thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>the city of yuma in this state has a record av...</td>\n",
       "      <td>arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>in 1963  live on  the art linkletter show   th...</td>\n",
       "      <td>mcdonald s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "      <td>signer of the dec  of indep   framer of the co...</td>\n",
       "      <td>john adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY  $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES  $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...  $200   \n",
       "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE  $200   \n",
       "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES  $200   \n",
       "\n",
       "                                            Question      Answer  \\\n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus   \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe   \n",
       "2  The city of Yuma in this state has a record av...     Arizona   \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's   \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams   \n",
       "\n",
       "                                      clean_question clean_answer  \n",
       "0  for the last 8 years of his life  galileo was ...   copernicus  \n",
       "1  no  2  1912 olympian  football star at carlisl...   jim thorpe  \n",
       "2  the city of yuma in this state has a record av...      arizona  \n",
       "3  in 1963  live on  the art linkletter show   th...   mcdonald s  \n",
       "4  signer of the dec  of indep   framer of the co...   john adams  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalize text columns\n",
    "jeopardy['clean_question'] = jeopardy['Question'].apply(\n",
    "    normalize_text)\n",
    "jeopardy['clean_answer'] = jeopardy['Answer'].apply(\n",
    "    normalize_text)\n",
    "# view updates\n",
    "jeopardy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need to normalize the non-text columns. Most of the columns are initially string types, but some of these contain numeric and date-time information that would be easier to manipulate and analyze if converted to the appropriate type. Therefore, we normalize the `Value` and `Air Date` columns, reformatting the `Value` entries as integers and the `Air Date` entries as datetime objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define numeric normalization function\n",
    "def normalize_num(text):\n",
    "    \"\"\"\n",
    "    Normalize numeric text by removing punctuation and converting \n",
    "    to integer type.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        Numeric text to be normalized.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        Normalized numeric text.\n",
    "    \"\"\"\n",
    "\n",
    "    text = re.sub('\\W', ' ', text)\n",
    "    try:\n",
    "        text = int(text)\n",
    "    except Exception:\n",
    "        text = 0\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# normalize `Value` column\n",
    "jeopardy['clean_value'] = jeopardy['Value'].apply(\n",
    "    normalize_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# normalize `Air Date` column\n",
    "jeopardy['Air Date'] = pd.to_datetime(jeopardy['Air Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Show Number                int64\n",
       "Air Date          datetime64[ns]\n",
       "Round                     object\n",
       "Category                  object\n",
       "Value                     object\n",
       "Question                  object\n",
       "Answer                    object\n",
       "clean_question            object\n",
       "clean_answer              object\n",
       "clean_value                int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check column types\n",
    "jeopardy.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Investigating Study Strategies\n",
    "\n",
    "Now that we've cleaned our dataset, we are ready to begin analyzing it. We want to use the data to investigate the best study strategies that are likely to maximize our winnings potential. The analysis should hopefully help us decide whether it is more worthwhile to study past questions or general knowledge, or if we should not even bother studying at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking for Answers in Questions\n",
    "\n",
    "One metric of interest is the relative frequency with which the answer appears in the question. This metric will help us to determine our chances of correctly guessing from the question alone an answer we do not know. If this metric is large, we may not need to study at all; instead, we can simply guess the answer each time based on the wording of the question. \n",
    "\n",
    "We calculate this metric by defining a function that measures the fraction of words in an individual answer that appear in the corresponding question. We then apply this function to each question-answer pair in the dataset and calculate the mean of the resulting distribution of answer-in-question fractions. If this mean is close to one, then all or most of the answer appears in the question very often, and we can safely guess the answers based on the wordings of the questions without studying. If the mean is close to zero, however, then the answer can rarely be found in the question, and we will have to develop a study strategy to prepare for the show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def frac_ans_in_q(row):\n",
    "    \"\"\"\n",
    "    Calculate the fraction of words in the answer that appear in \n",
    "    the question.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    row : pandas.Series\n",
    "        Row of dataframe containing questions and answers.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Fraction of answer appearing in question.\n",
    "    \"\"\"\n",
    "    \n",
    "    # split answer and question into lists\n",
    "    split_answer = row['clean_answer'].split()\n",
    "    split_question = row['clean_question'].split()\n",
    "    \n",
    "    # remove 'the' instances from answer list\n",
    "    split_answer = [answer for answer in split_answer if \n",
    "                    answer != 'the']\n",
    "    \n",
    "    # avoid dividing by zero\n",
    "    if len(split_answer) == 0:\n",
    "        return 0\n",
    "    \n",
    "    # loop through answer list\n",
    "    match_count = 0\n",
    "    for answer in split_answer:\n",
    "        if answer in split_question:\n",
    "            match_count += 1\n",
    "            \n",
    "    # find fraction of answer contained in question\n",
    "    return match_count / len(split_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate answer-in-question fraction for each row\n",
    "jeopardy['answer_in_question'] = jeopardy.apply(\n",
    "    frac_ans_in_q, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06229526885934705"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_ans_in_q = jeopardy['answer_in_question'].mean()\n",
    "mean_ans_in_q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, only 6% of the answer appears in each question. In other words, the answer only appears in the question about 6% of the time, which is not a large enough percentage for us to hope to win by simply guessing all of the answers from the context of the questions alone. It looks like we'll have to study for the show after all..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considering Recycled Questions\n",
    "\n",
    "Another metric we may be interested in that could help us determine whether to studyd past questions is the frequency of recycled questions, or questions that are reused in multiple episodes throughout the show's run. \n",
    "\n",
    "Unfortunately, we cannot answer this question completely, since we are only working about 10% of the full Jeopardy question dataset, but we can still investigate this metric in the subset of data we do have. We will not have a concrete number for the frequency of recycled questions, but we should be able to get a general idea of whether questions are recycled often or not.\n",
    "\n",
    "Below, we sort the questions chronologically by air date and compare the meaningful terms in an individual question to the set of all meaningful terms from previously aired questions. The mean of the distribution of the fraction of terms in a question that appear in old questions gives us a rough measure of how much overlap there is between the words used in new questions and old, with a value close to one indicating a large overlap, and a value close to zero indicating a small or negligible overlap. \n",
    "\n",
    "Because this overlap is calculated based on individual words rather than phrases, however, it is not a clear indicator of whether questions have been fully recycled from individual past questions, or if they simply reuse words from many different past questions. Still, this overlap metric can indicate whether recycling questions is likely a rare occurrence, if the overlap is very small, or if it is a real possibility that we should investigate further, if the overlap is large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialize list of question overlap + set of terms\n",
    "question_overlap = []\n",
    "terms_used = set()\n",
    "\n",
    "# sort dataset by ascending air date\n",
    "jeopardy = jeopardy.sort_values(by=['Air Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# iterate through dataset rows\n",
    "for i, row in jeopardy.iterrows():\n",
    "    \n",
    "    # split question into list of terms\n",
    "    split_question = row['clean_question'].split()\n",
    "    \n",
    "    # remove (meaningless) terms with less than 6 characters\n",
    "    split_question = [q for q in split_question if \n",
    "                      len(q) >= 6]\n",
    "    \n",
    "    # calculate fraction of terms in question used previously\n",
    "    match_count = 0\n",
    "    for q in split_question:\n",
    "        if q in terms_used:\n",
    "            match_count += 1\n",
    "        terms_used.add(q)  # add term to set\n",
    "    if len(split_question) > 0:\n",
    "        match_count /= len(split_question)\n",
    "        \n",
    "    # add fraction to overlap list\n",
    "    question_overlap.append(match_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assign question overlap to column in dataset\n",
    "jeopardy['question_overlap'] = question_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.721603243720504"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate mean of question overlap\n",
    "mean_q_overlap = jeopardy['question_overlap'].mean()\n",
    "mean_q_overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average, about 70% of the terms used in new questions are recycled from previous questions. In other words, new questions overlap completely with terms used in previous questions about 70% of the time. Again, this metric does not yield enough information for us to determine that 70% of the questions are wholly recycled, but it is indicative of the recycling of many terms that appear in questions, which points to the possibility of question recycling. We should thus investigate this further.\n",
    "\n",
    "This result also tells us that we should probably dedicate some time to studying past questions, since it appears many of the same topics, if not the same questions, come up more than once. It is not unexpected, then, that we may encounter a question in our episode that is at least reminiscent of one of the past questions we will have studied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Targeting High-Value Questions\n",
    "\n",
    "Rather than studying all previous questions, we want to instead focus only on the high-value questions, i.e. those worth the most money. This will help us to increase the amount of our winnings when we are on the show.\n",
    "\n",
    "We can isolate specific terms that correspond to high-value questions, which will give us an idea of the topics to study to maximize our earning potential. We first divide the questions into two categories based on their monetary value: (1) low value, where the value is less than \\$800, and (2) high value, where the value is at least \\$800. We then count the numbers of times each term in our term set is used in a high-value question, a low-value question, and any question. From there, we can calculate the chi-squared value for our observed and expected high/low-value counts for each term, which we can use to identify the terms with statistically significant differences in usage between high- and low-value questions. \n",
    "\n",
    "If the chi-squared value of the term is small, or the p-value is large, the difference in usage is not statistically significant, and there is no observed relationship between the word and a particular value. On the other hand, if the chi-squared value is large, or the p-value is small, there is some statistically significant correlation between the word usage and its value, with the word more likely to be used in either high- or low-value questions.\n",
    "\n",
    "The procedure outlined above entails looping over every word in the term set, which is time-consuming, so we begin by testing a small sample of words only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define function to categorize question by value\n",
    "def value_type(row):\n",
    "    \"\"\"\n",
    "    Categorize question as high- or low-value.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    row : pandas.Series\n",
    "        Individual row of dataset.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        Integer value of question: 0 for low; 1 for high.\n",
    "    \"\"\"\n",
    "    \n",
    "    value = 0\n",
    "    if row['clean_value'] >= 800:\n",
    "        value = 1\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# apply value categorization to each row of dataframe\n",
    "jeopardy['high_value'] = jeopardy.apply(value_type, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define function to count high- and low-value occurrences of word\n",
    "def value_count(word):\n",
    "    \"\"\"\n",
    "    Return counts of occurrences of word in high- and low-value \n",
    "    questions.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    word : str\n",
    "        Word of which to count occurrences.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    high_count, low_count : int\n",
    "        Numbers of occurrences of word in high- and low-value\n",
    "        questions.\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize counts\n",
    "    low_count = 0\n",
    "    high_count = 0\n",
    "    \n",
    "    # iterate through dataset rows\n",
    "    for i, row in jeopardy.iterrows():\n",
    "        if word in row['clean_question'].split():\n",
    "            if row['high_value'] == 1:\n",
    "                high_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "    \n",
    "    return high_count, low_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['collided',\n",
       " 'shouldered',\n",
       " 'indians',\n",
       " 'arabella',\n",
       " 'calling',\n",
       " 'benetton',\n",
       " 'invigorate',\n",
       " 'fitzroy',\n",
       " 'allworthy',\n",
       " 'jeweler']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# randomly sample 10 elements from term set\n",
    "import random\n",
    "random.seed(1)\n",
    "comparison_terms = random.sample(terms_used, 10)\n",
    "comparison_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get counts for each term\n",
    "observed_expected = []\n",
    "for term in comparison_terms:\n",
    "    observed_expected.append(value_count(term))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (1, 0),\n",
       " (6, 6),\n",
       " (0, 1),\n",
       " (5, 8),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (0, 1),\n",
       " (1, 0),\n",
       " (3, 0)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get total high/low-value question counts\n",
    "high_value_count = jeopardy['high_value'].sum()\n",
    "low_value_count = jeopardy.shape[0] - high_value_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate chi-squared of value counts for each term\n",
    "from scipy.stats import chisquare\n",
    "import numpy as np\n",
    "\n",
    "chi_squared = []\n",
    "p_value = []\n",
    "\n",
    "for obs in observed_expected:\n",
    "    \n",
    "    # get total word count\n",
    "    total = obs[0] + obs[1]\n",
    "    \n",
    "    # get total word proportion across all questions\n",
    "    total_prop = total / jeopardy.shape[0]\n",
    "    \n",
    "    # get expected counts\n",
    "    exp_high_count = total_prop * high_value_count\n",
    "    exp_low_count = total_prop * low_value_count\n",
    "    \n",
    "    # compute chi-squared value and p-value\n",
    "    observed = np.array([obs[0], obs[1]])\n",
    "    expected = np.array([exp_high_count, exp_low_count])\n",
    "    chisq, pvalue = chisquare(observed, expected)\n",
    "    \n",
    "    # append values to lists\n",
    "    chi_squared.append(chisq)\n",
    "    p_value.append(pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6600813480534574,\n",
       " 1.5149647887323945,\n",
       " 0.5251384103575547,\n",
       " 0.6600813480534574,\n",
       " 0.00917892259470195,\n",
       " 0.6600813480534574,\n",
       " 0.6600813480534574,\n",
       " 0.6600813480534574,\n",
       " 1.5149647887323945,\n",
       " 4.544894366197182]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.41653122582698476,\n",
       " 0.2183830639074722,\n",
       " 0.4686579749653339,\n",
       " 0.41653122582698476,\n",
       " 0.9236741008612599,\n",
       " 0.41653122582698476,\n",
       " 0.41653122582698476,\n",
       " 0.41653122582698476,\n",
       " 0.2183830639074722,\n",
       " 0.03301705930176248]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the above ten randomly sampled terms, only one has a large enough chi-squared value, or a low enough p-value, to be considered statistically significant. The word \"jeweler\" has a chi-squared value of approximately 4.54 and a p-value of about 0.03. This is the only term in our small random sample with a p-value below threshold (0.05) for statistical significance. This indicates a significant distinction between usage in high- and low-value questions for this one particular term, although we can not tell from the significance alone whether the usage is larger for high- or low-value questions. \n",
    "\n",
    "Only 10% of our random sample indicates a statistically significant difference in usage for words between high- and low-value questions. However, we only sampled ten rows from our dataset, which is only 1/2000 of our data. We can't draw a reasonable conclusion from such a small sample. We should redo this chi-squared test across a larger sample of terms, but this would involve modifying our procedure to increase its speed, since our current method is too slow. We leave this for the future, along with some other ideas for better developing useful study strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this analysis, we determined it would suit us best to study for our upcoming appearance on the show \"Jeopardy\". At this point, it is clear we should study past questions, but since there are so many, we should find a way to narrow down the set of past questions to study. \n",
    "\n",
    "We are interested in maximizing our winnings, so we would like to focus on high-value questions about topics that occur frequently. We found analyzing by individual words yielded results that were too difficult to draw any meaninful conclusions from. We should instead try to search for common phrases when analyzing both the question overlap and the chi-squared of the high/low-value counts. \n",
    "\n",
    "We would also like to analyze the category data, looking at the most frequently used categories or the probability that a given category will occur in an episode or a specific round. This may help us to determine which topics to spend the most time studying.\n",
    "\n",
    "We leave these steps for the future."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
